{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8bd83-72b5-473e-8a00-6246b15b5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all audio files\n",
    "import glob\n",
    "\n",
    "audio_files = glob.glob(\"./data/audio_files/**/*.wav\", recursive=True)\n",
    "print(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68905b-743e-436c-a349-3a3c0883fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in excel file with annotations\n",
    "import pandas as pd\n",
    "\n",
    "filepath = './data/Recordings.xlsx'\n",
    "df_R1 = pd.read_excel(filepath, sheet_name=0)\n",
    "df_R1_L1 = pd.read_excel(filepath, sheet_name=1)\n",
    "df_R5 = pd.read_excel(filepath, sheet_name=2)\n",
    "df_R5_L1 = pd.read_excel(filepath, sheet_name=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc91d8-460c-4a4c-ae41-74d9a4afeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for trimming audio files\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def get_row_info(df, task):\n",
    "    \"\"\"\n",
    "    Returns the file name, offset, and duration of a given task\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe containing recording information\n",
    "    task : string\n",
    "        Task to get information for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    file_name : string\n",
    "        Name of the file\n",
    "    offset : float\n",
    "        Offset of the task\n",
    "    duration : float\n",
    "        Duration of the task\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = df['recording']\n",
    "    offset = df[task+'_start']\n",
    "    duration = df[task+'_end'] - df[task+'_start']\n",
    "    \n",
    "    return file_name, offset, duration\n",
    "\n",
    "def trim_files(df, audio_files, task, trimmed_files, offsets, checklist):\n",
    "    \"\"\"\n",
    "    Trims audio files based on annotated start and end times of a given task\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe containing recording information\n",
    "    audio_files : list\n",
    "        List of audio files\n",
    "    task : string\n",
    "        Task to get information for\n",
    "    trimmed_files : list\n",
    "        List of trimmed output audio files\n",
    "    offsets : list\n",
    "        List of offsets for the audio files\n",
    "    checklist : list\n",
    "        List of files where annotations are (partly) outside the duration of the audio file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_files : list\n",
    "        List of trimmed output audio files\n",
    "    offsets : list\n",
    "        List of offsets for the audio files\n",
    "    checklist : list\n",
    "        List of files where annotations are (partly) outside the duration of the audio file\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        file_name, offset, duration = get_row_info(row, task)\n",
    "        print(file_name)\n",
    "        \n",
    "        # find file path of audio file\n",
    "        file_path = [x for x in audio_files if file_name in x][0]\n",
    "        print(file_path)\n",
    "        group = '/'.join(file_path.split('/')[-2:-1])\n",
    "        path = './trimmed_audio/' + group + '/' + task + '/'\n",
    "\n",
    "        # read audio(with offset & duration)\n",
    "        duration_sec = librosa.get_duration(filename=file_path)\n",
    "        if (offset + duration) > duration_sec:\n",
    "            print(\"WARNING, end of \", str(task), \"annotation is outside file\")\n",
    "            checklist.append(file_path)\n",
    "        y, sr = librosa.load(file_path, offset=offset, duration=duration)\n",
    "    \n",
    "        # write audio signal to new file\n",
    "        new_filename = path + file_name + '_' + task + '.wav'\n",
    "        trimmed_files.append(new_filename)\n",
    "        offsets.append(offset)\n",
    "        sf.write(new_filename, y, sr)\n",
    "        print(new_filename + \" written\")\n",
    "    return trimmed_files, offsets, checklist\n",
    "\n",
    "def trim_all(all_dfs, tasks):\n",
    "    \"\"\"\n",
    "    Trims all audio files for all tasks\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_dfs : list\n",
    "        List of dataframes containing recording information\n",
    "    tasks : list\n",
    "        List of tasks to get information for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trimmed_files : list\n",
    "        List of trimmed output audio files\n",
    "    offsets : list\n",
    "        List of offsets for the audio files\n",
    "    checklist : list\n",
    "        List of files where annotations are (partly) outside the duration of the audio file\n",
    "    \"\"\"\n",
    "\n",
    "    trimmed_files = []\n",
    "    offsets = []\n",
    "    checklist = []\n",
    "\n",
    "    # trim all files for all tasks\n",
    "    for task in tasks:\n",
    "        for df in all_dfs:\n",
    "            trimmed_files, offsets, checklist = trim_files(df, audio_files, task, trimmed_files, offsets, checklist)\n",
    "\n",
    "    return trimmed_files, offsets, checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1d3a5-9383-4ec7-9876-0a54527406cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim all audio files\n",
    "\n",
    "all_dfs = [df_R1, df_R1_L1, df_R5, df_R5_L1]\n",
    "tasks = ['formal', 'informal']\n",
    "\n",
    "trimmed_files, offsets, checklist = trim_all(all_dfs, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for transcribing trimmed audio files\n",
    "\n",
    "def run_whisperx(audio_file, device, compute_type, offset):\n",
    "    \"\"\"\n",
    "    Transcribes audio file using whisperx, and change the start and end times to match the original audio file \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_file : string\n",
    "        Path to audio file\n",
    "    device : string\n",
    "        Device to use for transcription (cuda or cpu)\n",
    "    compute_type : string\n",
    "        Compute type to use for transcription (float16 or int8)\n",
    "    offset : float\n",
    "        start time of the audio segment\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        Dictionary containing the transcription results\n",
    "    \"\"\"\n",
    "\n",
    "    audio_whisperx = whisperx.load_audio(audio_file)\n",
    "    model = whisperx.load_model(whisperx_model, device, compute_type=compute_type)\n",
    "    result = model.transcribe(audio_whisperx, batch_size=batch_size)\n",
    "    model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "    result = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device, return_char_alignments=False)\n",
    "    \n",
    "    for segment in result[\"segments\"]:\n",
    "        del segment['words']\n",
    "        segment['start'] += offset\n",
    "        segment['end'] += offset\n",
    "        \n",
    "    return result\n",
    "\n",
    "def transcribe_all(trimmed_files, offsets, device, compute_type, writer_options):\n",
    "    \"\"\"\n",
    "    Transcribes all audio files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trimmed_files : list\n",
    "        List of trimmed audio files\n",
    "    offsets : list\n",
    "        List of offsets for the audio files\n",
    "    device : string\n",
    "        Device to use for transcription (cuda or cpu)\n",
    "    compute_type : string\n",
    "        Compute type to use for transcription (float16 or int8)\n",
    "    writer_options : dict\n",
    "        Dictionary containing the writer options\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\" \n",
    "\n",
    "    for idx, file in enumerate(trimmed_files):\n",
    "        audio_file = file\n",
    "        print(file)\n",
    "        result = run_whisperx(audio_file, device, compute_type, offset = offsets[idx])\n",
    "\n",
    "        output_directory = \"/data/volume_2/transcripts/\" + '/'.join(file.split('/')[-3:-2]) + '/'\n",
    "        writer = whisper.utils.get_writer(\"all\", output_directory)\n",
    "        writer(result, audio_file, writer_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ac1c4-1c00-4a64-a089-c46c112b159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all required Whisper variables and transcribe all audio files\n",
    "\n",
    "import whisper\n",
    "import whisperx\n",
    "import gc\n",
    "\n",
    "device = \"cuda\" \n",
    "batch_size = 16                 # reduce if low on GPU mem\n",
    "compute_type = \"float16\"        # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "whisperx_model = \"large-v2\"     # options: \"base\", \"small\", \"medium\"\n",
    "\n",
    "writer_options = {\"max_line_width\":None,\n",
    "                  \"max_line_count\":None,\n",
    "                  \"highlight_words\":None}\n",
    "\n",
    "#Create transcripts for all audio files\n",
    "transcribe_all(trimmed_files, offsets, device, compute_type, writer_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
